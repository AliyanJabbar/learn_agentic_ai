{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500981a6",
   "metadata": {},
   "source": [
    "# 1. Using Openrouter's api directly\n",
    "** Openrouter unifieds the interfaces means that we only need one api key of openrouter rather than having multiple like seperate for gemini and deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352d75dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1748701566-EcPJXpHDUfWwRGYHm6KE', 'provider': 'Google AI Studio', 'model': 'google/gemini-2.0-flash-001', 'object': 'chat.completion', 'created': 1748701566, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'STOP', 'index': 0, 'message': {'role': 'assistant', 'content': '## What is OpenRouter?\\n\\nOpenRouter is a unified interface to use a variety of large language models (LLMs) from different providers through a single API. It acts as an aggregator, allowing you to easily switch between models like OpenAI\\'s GPT series, Anthropic\\'s Claude, Google\\'s PaLM, and many others, without needing to change your code significantly.\\n\\nHere\\'s a breakdown of its key benefits:\\n\\n*   **Access to Multiple Models:**  You can experiment with various models to find the best one for your specific application.\\n*   **Simplified API Integration:**  Instead of having to learn and use different APIs for each model provider, OpenRouter offers a consistent API.\\n*   **Cost Optimization:** You can compare pricing and performance of different models to optimize your costs.  They also implement dynamic routing based on cost and latency.\\n*   **Model Diversity:**  Explore less mainstream, potentially more specialized models.\\n*   **Fallback Solutions:**  If one provider experiences downtime, OpenRouter can automatically switch to another, ensuring continuity.\\n* **API Key Management**: OpenRouter handles the complexity of storing and managing API keys.\\n\\nIn essence, OpenRouter provides a convenient platform for developing applications that leverage the power of LLMs in a more flexible and cost-effective manner.\\n\\n## Preferred Model for Studying AI Agents\\n\\nChoosing the \"best\" model for studying AI agents depends on your specific goals and priorities. However, here are a few factors to consider and some popular models that are often recommended:\\n\\n**Key Considerations:**\\n\\n*   **Function Calling/Tool Use:** AI agents often need to interact with the real world through tools or functions. Models that are specifically trained for this are very good.\\n*   **Reasoning Ability:** Agents need to be able to understand the user\\'s goals, plan steps to achieve them, and troubleshoot problems. Strong reasoning capabilities are essential.\\n*   **Context Window:**  The size of the context window (the amount of text the model can remember at once) determines how complex the agent\\'s reasoning and memory can be.  Larger context windows allow for more sophisticated agents.\\n*   **Cost:**  AI agent development can be iterative and involve a lot of experimentation. Running hundreds or thousands of requests on very expensive models can quickly become costly.\\n*   **Availability:**  Some models are more readily available than others, with fewer rate limits or access restrictions.\\n*   **Ease of Use/Documentation:**  A well-documented model and a supportive community can significantly speed up your learning process.\\n*   **Safety:**  AI agents can be used for harmful purposes if not designed and operated safely. The model\\'s safeguards against generating inappropriate or dangerous outputs should be evaluated.\\n\\n**Recommended Models (and why):**\\n\\nHere\\'s a breakdown, with the caveat that model capabilities are rapidly evolving, so it\\'s important to stay up-to-date:\\n\\n1.  **GPT-4 and later versions:**\\n    *   **Pros:** Excellent reasoning abilities, strong tool use capabilities, large context window (especially with GPT-4 Turbo).  Well-documented, widely supported, and a large community.  Generally considered among the most capable models available.\\n    *   **Cons:** Relatively expensive.\\n\\n2.  **GPT-3.5 Turbo:**\\n    *   **Pros:**  A good balance of performance and cost.  Function calling is great. Very strong ecosystem and community support.\\n    *   **Cons:**  Less powerful reasoning than GPT-4.\\n\\n3.  **Claude (particularly Claude 3 Opus):**\\n    *   **Pros:** Known for strong reasoning, long context windows (especially with Claude 3), and a focus on safety. Excellent conversational abilities.\\n    *   **Cons:** Can sometimes be more expensive than some GPT models.\\n\\n4.  **Gemini Pro:**\\n    *   **Pros:** Native multimodality. Good reasoning abilities and a lower cost compared to top-tier models, integrated with Google ecosystem.\\n    *   **Cons:** Tool use abilities are more experimental than with GPT-4.\\n\\n**General Advice:**\\n\\n*   **Start with a less expensive model:**  Begin your experimentation with a more affordable model like GPT-3.5 Turbo, Gemini Pro, or a similar model to get a feel for the basics of AI agent development.  Then, when you\\'re ready to implement more complex agents, consider moving to a more powerful (and potentially more expensive) model like GPT-4 or Claude 3 Opus.\\n*   **Focus on Function Calling/Tool Use:**  Many models like GPT3.5 Turbo and GPT4 have dedicated tool_calling functionalities, which are crucial for having AI agents interact with the real world through APIs.\\n*   **Iterate and Experiment:**  The \"best\" model is highly dependent on the specific task the agent needs to perform. Regularly evaluate the model\\'s performance and adjust your approach based on the results.\\n*   **Use OpenRouter for flexibility and cost management:**  OpenRouter gives you the ability to easily switch between models and compare pricing.  This is very valuable during the experimentation and development process.\\n* **Consider the broader ecosystem:** OpenAI has libraries like LangChain which can simplify many agent development tasks. This factor might influence your model choice.\\n\\nIn conclusion, there is no one-size-fits-all answer, but GPT-4 and GPT-3.5 Turbo from OpenAI, the Claude series from Anthropic, and the Gemini series from Google are all strong contenders for developing AI agents, each with its own strengths and weaknesses. Use OpenRouter to explore these models and ultimately choose the one that best suits your needs and budget. Focus on function calling, reasoning abilities, context window size, and safety considerations throughout your development process.\\n', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 1208, 'total_tokens': 1225}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# OPENROUTER_API_KEY = os.getenv(\"OPEN_AI_AGENT_KEY\")\n",
    "# OPENROUTER_API_KEY = (\n",
    "#     \"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\"\n",
    "# )\n",
    "OPENROUTER_API_KEY = os.getenv('OPEN_AI_AGENT_KEY')\n",
    "\n",
    "\n",
    "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "# MODEL = \"deepseek/deepseek-chat-v3-0324\" # when using deepseek\n",
    "MODEL = \"google/gemini-2.0-flash-001\"  # when using gemini\n",
    "\n",
    "\n",
    "# Some other free models on 26th March:\n",
    "# https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free\n",
    "# https://openrouter.ai/google/gemini-2.5-pro-exp-03-25:free\n",
    "\n",
    "\n",
    "response = requests.post(\n",
    "    url=f\"{BASE_URL}/chat/completions\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\", #telling openrouter's server that : \"Hey, I’m an authorized user. Here’s my key: please let me use your API.\"\n",
    "    },\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"model\": MODEL,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"what is openrouter? which model is preferred when studying how to make ai agents?  \"}],\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "print(response.json()) #printing all the response data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200a71c",
   "metadata": {},
   "source": [
    "showing what is important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e121718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## What is OpenRouter?\n",
      "\n",
      "OpenRouter is a unified interface to use a variety of large language models (LLMs) from different providers through a single API. It acts as an aggregator, allowing you to easily switch between models like OpenAI's GPT series, Anthropic's Claude, Google's PaLM, and many others, without needing to change your code significantly.\n",
      "\n",
      "Here's a breakdown of its key benefits:\n",
      "\n",
      "*   **Access to Multiple Models:**  You can experiment with various models to find the best one for your specific application.\n",
      "*   **Simplified API Integration:**  Instead of having to learn and use different APIs for each model provider, OpenRouter offers a consistent API.\n",
      "*   **Cost Optimization:** You can compare pricing and performance of different models to optimize your costs.  They also implement dynamic routing based on cost and latency.\n",
      "*   **Model Diversity:**  Explore less mainstream, potentially more specialized models.\n",
      "*   **Fallback Solutions:**  If one provider experiences downtime, OpenRouter can automatically switch to another, ensuring continuity.\n",
      "* **API Key Management**: OpenRouter handles the complexity of storing and managing API keys.\n",
      "\n",
      "In essence, OpenRouter provides a convenient platform for developing applications that leverage the power of LLMs in a more flexible and cost-effective manner.\n",
      "\n",
      "## Preferred Model for Studying AI Agents\n",
      "\n",
      "Choosing the \"best\" model for studying AI agents depends on your specific goals and priorities. However, here are a few factors to consider and some popular models that are often recommended:\n",
      "\n",
      "**Key Considerations:**\n",
      "\n",
      "*   **Function Calling/Tool Use:** AI agents often need to interact with the real world through tools or functions. Models that are specifically trained for this are very good.\n",
      "*   **Reasoning Ability:** Agents need to be able to understand the user's goals, plan steps to achieve them, and troubleshoot problems. Strong reasoning capabilities are essential.\n",
      "*   **Context Window:**  The size of the context window (the amount of text the model can remember at once) determines how complex the agent's reasoning and memory can be.  Larger context windows allow for more sophisticated agents.\n",
      "*   **Cost:**  AI agent development can be iterative and involve a lot of experimentation. Running hundreds or thousands of requests on very expensive models can quickly become costly.\n",
      "*   **Availability:**  Some models are more readily available than others, with fewer rate limits or access restrictions.\n",
      "*   **Ease of Use/Documentation:**  A well-documented model and a supportive community can significantly speed up your learning process.\n",
      "*   **Safety:**  AI agents can be used for harmful purposes if not designed and operated safely. The model's safeguards against generating inappropriate or dangerous outputs should be evaluated.\n",
      "\n",
      "**Recommended Models (and why):**\n",
      "\n",
      "Here's a breakdown, with the caveat that model capabilities are rapidly evolving, so it's important to stay up-to-date:\n",
      "\n",
      "1.  **GPT-4 and later versions:**\n",
      "    *   **Pros:** Excellent reasoning abilities, strong tool use capabilities, large context window (especially with GPT-4 Turbo).  Well-documented, widely supported, and a large community.  Generally considered among the most capable models available.\n",
      "    *   **Cons:** Relatively expensive.\n",
      "\n",
      "2.  **GPT-3.5 Turbo:**\n",
      "    *   **Pros:**  A good balance of performance and cost.  Function calling is great. Very strong ecosystem and community support.\n",
      "    *   **Cons:**  Less powerful reasoning than GPT-4.\n",
      "\n",
      "3.  **Claude (particularly Claude 3 Opus):**\n",
      "    *   **Pros:** Known for strong reasoning, long context windows (especially with Claude 3), and a focus on safety. Excellent conversational abilities.\n",
      "    *   **Cons:** Can sometimes be more expensive than some GPT models.\n",
      "\n",
      "4.  **Gemini Pro:**\n",
      "    *   **Pros:** Native multimodality. Good reasoning abilities and a lower cost compared to top-tier models, integrated with Google ecosystem.\n",
      "    *   **Cons:** Tool use abilities are more experimental than with GPT-4.\n",
      "\n",
      "**General Advice:**\n",
      "\n",
      "*   **Start with a less expensive model:**  Begin your experimentation with a more affordable model like GPT-3.5 Turbo, Gemini Pro, or a similar model to get a feel for the basics of AI agent development.  Then, when you're ready to implement more complex agents, consider moving to a more powerful (and potentially more expensive) model like GPT-4 or Claude 3 Opus.\n",
      "*   **Focus on Function Calling/Tool Use:**  Many models like GPT3.5 Turbo and GPT4 have dedicated tool_calling functionalities, which are crucial for having AI agents interact with the real world through APIs.\n",
      "*   **Iterate and Experiment:**  The \"best\" model is highly dependent on the specific task the agent needs to perform. Regularly evaluate the model's performance and adjust your approach based on the results.\n",
      "*   **Use OpenRouter for flexibility and cost management:**  OpenRouter gives you the ability to easily switch between models and compare pricing.  This is very valuable during the experimentation and development process.\n",
      "* **Consider the broader ecosystem:** OpenAI has libraries like LangChain which can simplify many agent development tasks. This factor might influence your model choice.\n",
      "\n",
      "In conclusion, there is no one-size-fits-all answer, but GPT-4 and GPT-3.5 Turbo from OpenAI, the Claude series from Anthropic, and the Gemini series from Google are all strong contenders for developing AI agents, each with its own strengths and weaknesses. Use OpenRouter to explore these models and ultimately choose the one that best suits your needs and budget. Focus on function calling, reasoning abilities, context window size, and safety considerations throughout your development process.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = response.json()\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df137e1f",
   "metadata": {},
   "source": [
    "# 2. Using OpenAI Agent SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0b4a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For students on OpenRouter, consider models like OpenChat, Mistral OpenHermes, or Nous Hermes due to their balance of performance and cost.\n",
      "If you're getting Gemini and DeepSeek for free, use them directly as they're likely more cost-effective.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio # Python’s standard library for asynchronous programming.\n",
    "from openai import AsyncOpenAI #: An async client to call OpenAI-like APIs.\n",
    "from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled\n",
    "\n",
    "nest_asyncio.apply() #for asyncronous python programming\n",
    "# creating an async openai client\n",
    "# This client will be used to interact with the OpenRouter API\n",
    "client = AsyncOpenAI(\n",
    "    api_key=OPENROUTER_API_KEY, #infering from the above code \n",
    "    base_url=BASE_URL #same here\n",
    ")\n",
    "\n",
    "set_tracing_disabled(disabled=True) #This disables any tracing/logging features inside the agent framework.\n",
    "\n",
    "async def main():\n",
    "    # This agent will use the custom LLM provider\n",
    "    agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"You only respond to the point in two to three lines.\", # haikus -> poetry form.\n",
    "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=client),\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"which is the best free model to use with openrouter for students. what if I am using gemini and deepseek for free?\",\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
